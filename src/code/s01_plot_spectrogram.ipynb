{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This script processes audio files in a given directory, extracts spectrograms, and allows you to visualize and play audio files. This is particularly helpful for initial data exploration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 125,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import random\n",
                "from typing import List, Tuple\n",
                "import torchaudio\n",
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "from typing import Any, Optional\n",
                "import numpy as np\n",
                "from scipy import signal\n",
                "from speechbrain.augment.time_domain import Resample\n",
                "from IPython.display import Audio, display\n",
                "\n",
                "def resample_audios(\n",
                "    waveform: torch.Tensor,\n",
                "    sampling_rate: int,\n",
                "    resample_rate: int,\n",
                "    lowcut: Optional[float] = None,\n",
                "    order: int = 4,\n",
                ") -> torch.Tensor:\n",
                "    \"\"\"Resamples a list of audio signals to a given sampling rate.\n",
                "\n",
                "    Args:\n",
                "        waveform (torch.Tensor): Audio waveform tensor.\n",
                "        sampling_rate (int): Original sampling rate.\n",
                "        resample_rate (int): Target sampling rate.\n",
                "        lowcut (float, optional): Low cut frequency for IIR filter.\n",
                "        order (int, optional): Order of the IIR filter. Defaults to 4.\n",
                "\n",
                "    Returns:\n",
                "        torch.Tensor: Resampled audio tensor.\n",
                "    \"\"\"\n",
                "    if lowcut is None:\n",
                "        lowcut = resample_rate / 2 - 100\n",
                "    sos = signal.butter(order, lowcut, btype=\"low\", output=\"sos\", fs=resample_rate)\n",
                "\n",
                "    channels = []\n",
                "    for channel in waveform:\n",
                "        filtered_channel = torch.from_numpy(signal.sosfiltfilt(sos, channel.numpy()).copy()).float()\n",
                "        resampler = Resample(orig_freq=sampling_rate, new_freq=resample_rate)\n",
                "        resampled_channel = resampler(filtered_channel.unsqueeze(0)).squeeze(0)\n",
                "        channels.append(resampled_channel)\n",
                "\n",
                "    resampled_waveform = torch.stack(channels)\n",
                "    return resampled_waveform\n",
                "\n",
                "def get_wav_files(folder: str) -> List[str]:\n",
                "    \"\"\"Get all .wav files in the given folder.\n",
                "\n",
                "    Args:\n",
                "        folder (str): The path to the folder.\n",
                "\n",
                "    Returns:\n",
                "        List[str]: A list of .wav file paths.\n",
                "    \"\"\"\n",
                "    return [os.path.join(folder, file) for file in os.listdir(folder) if file.endswith('.wav')]\n",
                "\n",
                "def pick_random_file(files: List[str]) -> str:\n",
                "    \"\"\"Pick a random file from the list of files.\n",
                "\n",
                "    Args:\n",
                "        files (List[str]): A list of file paths.\n",
                "\n",
                "    Returns:\n",
                "        str: The path to the randomly picked file.\n",
                "    \"\"\"\n",
                "    return random.choice(files)\n",
                "\n",
                "def load_audio(file_path: str) -> Tuple[torch.Tensor, int]:\n",
                "    \"\"\"Load the audio file using torchaudio.\n",
                "\n",
                "    Args:\n",
                "        file_path (str): The path to the audio file.\n",
                "\n",
                "    Returns:\n",
                "        Tuple[torch.Tensor, int]: The audio tensor and the sample rate.\n",
                "    \"\"\"\n",
                "    waveform, sample_rate = torchaudio.load(file_path)\n",
                "\n",
                "    return waveform, sample_rate\n",
                "\n",
                "def extract_spectrogram_from_audio(\n",
                "    waveform: torch.Tensor,\n",
                "    n_fft: int = 1024,\n",
                "    win_length: Optional[int] = None,\n",
                "    hop_length: Optional[int] = None,\n",
                ") -> torch.Tensor:\n",
                "    \"\"\"Extract spectrograms from an audio.\n",
                "\n",
                "    Args:\n",
                "        waveform (torch.Tensor): Audio waveform tensor.\n",
                "        n_fft (int): Size of FFT, creates n_fft // 2 + 1 bins. Default is 1024.\n",
                "        win_length (int): Window size. Default is None, using n_fft.\n",
                "        hop_length (int): Length of hop between STFT windows. Default is None, using win_length // 2.\n",
                "\n",
                "    Returns:\n",
                "        torch.Tensor: spectrogram tensor.\n",
                "    \"\"\"\n",
                "    if win_length is None:\n",
                "        win_length = n_fft\n",
                "    if hop_length is None:\n",
                "        hop_length = win_length // 2\n",
                "    spectrogram = torchaudio.transforms.Spectrogram(\n",
                "        n_fft=n_fft,\n",
                "        win_length=win_length,\n",
                "        hop_length=hop_length,\n",
                "    )\n",
                "    try:\n",
                "        return spectrogram(waveform).squeeze(0)\n",
                "    except RuntimeError:\n",
                "        return torch.tensor([])\n",
                "\n",
                "\n",
                "def extract_mel_spectrogram_from_audio(\n",
                "    waveform: torch.Tensor,\n",
                "    sampling_rate: int,\n",
                "    n_fft: Optional[int] = 1024,\n",
                "    win_length: Optional[int] = None,\n",
                "    hop_length: Optional[int] = None,\n",
                "    n_mels: int = 128,\n",
                ") -> torch.Tensor:\n",
                "    \"\"\"Extract mel spectrograms from a list of audio objects.\n",
                "\n",
                "    Args:\n",
                "        waveform (torch.Tensor): Audio waveform tensor.\n",
                "        sampling_rate (int): Sampling rate of the audio.\n",
                "        n_fft (int): Size of FFT, creates n_fft // 2 + 1 bins. Default is 1024.\n",
                "        win_length (int): Window size. Default is None, using n_fft.\n",
                "        hop_length (int): Length of hop between STFT windows. Default is None, using win_length // 2.\n",
                "        n_mels (int): Number of mel filter banks. Default is 128.\n",
                "\n",
                "    Returns:\n",
                "        torch.Tensor: the mel spectrograms.\n",
                "    \"\"\"\n",
                "    if win_length is None:\n",
                "        win_length = n_fft\n",
                "    if hop_length is None:\n",
                "        if win_length is not None:\n",
                "            hop_length = win_length // 2\n",
                "        else:\n",
                "            raise ValueError(\"win_length cannot be None\")\n",
                "    try:\n",
                "        mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
                "            sample_rate=sampling_rate,\n",
                "            n_fft=n_fft,\n",
                "            win_length=win_length,\n",
                "            hop_length=hop_length,\n",
                "            n_mels=n_mels,\n",
                "        )(waveform)\n",
                "        return mel_spectrogram.squeeze(0)\n",
                "    except RuntimeError:\n",
                "        return torch.tensor([])\n",
                "\n",
                "\n",
                "def plot_specgram(\n",
                "    waveform: torch.Tensor,\n",
                "    sampling_rate: int,\n",
                "    mel_scale: bool = False,\n",
                "    title: str = \"Spectrogram\",\n",
                "    **spect_kwargs: Any,\n",
                ") -> None:\n",
                "    \"\"\"Plots the spectrogram of an audio waveform.\n",
                "\n",
                "    Args:\n",
                "        waveform (torch.Tensor): The audio waveform tensor.\n",
                "        sampling_rate (int): The sampling rate of the audio.\n",
                "        mel_scale (bool): Whether to plot a mel spectrogram or a regular spectrogram.\n",
                "        title (str): Title of the spectrogram plot.\n",
                "        **spect_kwargs: Additional keyword arguments for spectrogram extraction.\n",
                "    \"\"\"\n",
                "\n",
                "    def _power_to_db(\n",
                "        spectrogram: np.ndarray, ref: float = 1.0, amin: float = 1e-10, top_db: float = 80.0\n",
                "    ) -> np.ndarray:\n",
                "        \"\"\"Converts a power spectrogram to decibel (dB) units.\"\"\"\n",
                "        S = np.asarray(spectrogram)\n",
                "\n",
                "        if amin <= 0:\n",
                "            raise ValueError(\"amin must be strictly positive\")\n",
                "\n",
                "        if np.issubdtype(S.dtype, np.complexfloating):\n",
                "            magnitude = np.abs(S)\n",
                "        else:\n",
                "            magnitude = S\n",
                "\n",
                "        ref_value = np.abs(ref)\n",
                "        log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
                "        log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
                "\n",
                "        if top_db is not None:\n",
                "            log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
                "\n",
                "        return log_spec\n",
                "\n",
                "    # Extract the spectrogram\n",
                "    if mel_scale:\n",
                "        spectrogram = extract_mel_spectrogram_from_audio(waveform, sampling_rate, **spect_kwargs)\n",
                "        y_axis_label = \"Mel Frequency\"\n",
                "    else:\n",
                "        spectrogram = extract_spectrogram_from_audio(waveform, **spect_kwargs)\n",
                "        y_axis_label = \"Frequency [Hz]\"\n",
                "\n",
                "    if spectrogram.ndim != 2:\n",
                "        raise ValueError(\"Spectrogram must be a 2D tensor for plotting.\")\n",
                "\n",
                "    # Determine time and frequency scale\n",
                "    num_frames = spectrogram.size(1)\n",
                "    num_freq_bins = spectrogram.size(0)\n",
                "\n",
                "    # Time axis in seconds\n",
                "    time_axis = (waveform.size(-1) / sampling_rate) * (torch.arange(0, num_frames).float() / num_frames)\n",
                "\n",
                "    # Frequency axis in Hz (for non-mel spectrograms)\n",
                "    if mel_scale:\n",
                "        freq_axis = torch.arange(num_freq_bins)  # For mel spectrogram, keep the bins as discrete values\n",
                "    else:\n",
                "        freq_axis = torch.linspace(0, sampling_rate / 2, num_freq_bins)\n",
                "\n",
                "    plt.figure(figsize=(10, 4))\n",
                "    plt.imshow(\n",
                "        _power_to_db(spectrogram.numpy()),\n",
                "        aspect=\"auto\",\n",
                "        origin=\"lower\",\n",
                "        extent=(float(time_axis[0]), float(time_axis[-1]), float(freq_axis[0]), float(freq_axis[-1])),\n",
                "        cmap=\"viridis\",\n",
                "    )\n",
                "    plt.colorbar(label=\"Magnitude (dB)\")\n",
                "    plt.title(title)\n",
                "    plt.ylabel(y_axis_label)\n",
                "    plt.xlabel(\"Time [Sec]\")\n",
                "    plt.show(block=False)\n",
                "\n",
                "def play_audio(waveform: torch.Tensor, sampling_rate: int) -> None:\n",
                "    \"\"\"Plays an audio file.\n",
                "\n",
                "    Args:\n",
                "        waveform (torch.Tensor): The audio waveform tensor.\n",
                "        sampling_rate (int): The sampling rate of the audio.\n",
                "\n",
                "    Raises:\n",
                "        ValueError: If the number of channels is more than 2.\n",
                "    \"\"\"\n",
                "    waveform = waveform.numpy()\n",
                "    sample_rate = sampling_rate\n",
                "\n",
                "    num_channels = waveform.shape[0]\n",
                "    if num_channels == 1:\n",
                "        display(Audio(waveform[0], rate=sample_rate))\n",
                "    elif num_channels == 2:\n",
                "        display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
                "    else:\n",
                "        raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "folder_path = '../../data/ICBHI_final_database/labels'\n",
                "wav_files = get_wav_files(folder_path)\n",
                "if wav_files:\n",
                "    random_file = pick_random_file(wav_files)\n",
                "    print(f\"Randomly picked file: {random_file}\")\n",
                "    waveform, sample_rate = load_audio(random_file)\n",
                "    plot_specgram(waveform=waveform, sampling_rate=sample_rate, mel_scale=True)\n",
                "    play_audio(waveform, sample_rate)\n",
                "else:\n",
                "    print(\"No .wav files found in the folder.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "icbhi-2017-challenge-7lCVb28A-py3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
